{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519e7036",
   "metadata": {},
   "source": [
    "# 04 - Evaluaci√≥n y An√°lisis de Modelos\n",
    "\n",
    "Este notebook profundiza en la evaluaci√≥n de modelos con m√©tricas avanzadas.\n",
    "\n",
    "**Objetivos:**\n",
    "- M√©tricas detalladas de clasificaci√≥n\n",
    "- Curvas ROC y Precision-Recall\n",
    "- Matriz de confusi√≥n\n",
    "- Feature importance\n",
    "- An√°lisis de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"‚úÖ Librer√≠as cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce3992",
   "metadata": {},
   "source": [
    "## 1. Carga de Modelo y Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar mejor modelo\n",
    "model = joblib.load('./models/best_model.joblib')\n",
    "print(f\"‚úÖ Modelo cargado: {type(model).__name__}\")\n",
    "\n",
    "# Cargar datos de test\n",
    "X_test = pd.read_parquet('./data/X_test.parquet')\n",
    "y_test = pd.read_parquet('./data/y_test.parquet')['target']\n",
    "\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265dea4",
   "metadata": {},
   "source": [
    "## 2. Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Predicciones generadas: {len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c00b7d",
   "metadata": {},
   "source": [
    "## 3. Classification Report Detallado\n",
    "\n",
    "üí° **Copilot tip:** Analiza precision y recall seg√∫n tu caso de uso (ej: priorizar recall en detecci√≥n de fraude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte completo\n",
    "print(\"üìä Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_pred, target_names=['Clase 0', 'Clase 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb6a89a",
   "metadata": {},
   "source": [
    "## 4. Matriz de Confusi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=['Clase 0', 'Clase 1'],\n",
    "    yticklabels=['Clase 0', 'Clase 1'],\n",
    "    cbar_kws={'label': 'Frecuencia'}\n",
    ")\n",
    "plt.title('Matriz de Confusi√≥n', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Valor Real', fontsize=12)\n",
    "plt.xlabel('Valor Predicho', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# M√©tricas derivadas\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nüìà M√©tricas de la Matriz de Confusi√≥n:\")\n",
    "print(f\"   True Negatives (TN): {tn}\")\n",
    "print(f\"   False Positives (FP): {fp}\")\n",
    "print(f\"   False Negatives (FN): {fn}\")\n",
    "print(f\"   True Positives (TP): {tp}\")\n",
    "print(f\"   Specificity: {tn / (tn + fp):.4f}\")\n",
    "print(f\"   Sensitivity (Recall): {tp / (tp + fn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b349c",
   "metadata": {},
   "source": [
    "## 5. Curvas ROC y Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dca291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular curvas\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "# Visualizar\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ROC Curve\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[0].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "axes[1].plot(recall, precision, color='green', lw=2, label=f'PR curve (AP = {avg_precision:.3f})')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Recall', fontsize=12)\n",
    "axes[1].set_ylabel('Precision', fontsize=12)\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='lower left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3599c",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener importancias\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Top 15 features\n",
    "    top_features = importances.head(15)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Importancia', fontsize=12)\n",
    "    plt.title('Top 15 Features M√°s Importantes', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Top 10 Features:\")\n",
    "    for idx, row in importances.head(10).iterrows():\n",
    "        print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Modelo no tiene feature importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d8bd8",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar errores\n",
    "errors_df = X_test.copy()\n",
    "errors_df['y_true'] = y_test.values\n",
    "errors_df['y_pred'] = y_pred\n",
    "errors_df['y_proba'] = y_proba\n",
    "errors_df['error'] = errors_df['y_true'] != errors_df['y_pred']\n",
    "\n",
    "# Estad√≠sticas de errores\n",
    "n_errors = errors_df['error'].sum()\n",
    "error_rate = n_errors / len(errors_df)\n",
    "\n",
    "print(f\"\\n‚ùå An√°lisis de Errores:\")\n",
    "print(f\"   Total errores: {n_errors} / {len(errors_df)}\")\n",
    "print(f\"   Error rate: {error_rate:.2%}\")\n",
    "\n",
    "# Casos con mayor incertidumbre (probabilidad cercana a 0.5)\n",
    "uncertain = errors_df[errors_df['y_proba'].between(0.4, 0.6)].sort_values('y_proba')\n",
    "print(f\"\\nü§î Casos inciertos (prob entre 0.4-0.6): {len(uncertain)}\")\n",
    "\n",
    "if len(uncertain) > 0:\n",
    "    print(\"\\nPrimeros 5 casos m√°s inciertos:\")\n",
    "    display(uncertain[['y_true', 'y_pred', 'y_proba']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca26f6b",
   "metadata": {},
   "source": [
    "## 8. Distribuci√≥n de Probabilidades Predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histograma por clase\n",
    "plt.hist(y_proba[y_test == 0], bins=50, alpha=0.6, label='Clase 0 (Real)', color='blue')\n",
    "plt.hist(y_proba[y_test == 1], bins=50, alpha=0.6, label='Clase 1 (Real)', color='red')\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Threshold = 0.5')\n",
    "plt.xlabel('Probabilidad Predicha', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.title('Distribuci√≥n de Probabilidades Predichas por Clase Real', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09ad6f",
   "metadata": {},
   "source": [
    "## 9. Resumen Final\n",
    "\n",
    "**M√©tricas clave:**\n",
    "- ‚úÖ AUC-ROC: Mide capacidad de discriminaci√≥n\n",
    "- ‚úÖ Precision-Recall: √ötil en datasets desbalanceados\n",
    "- ‚úÖ Feature Importance: Interpretabilidad del modelo\n",
    "- ‚úÖ An√°lisis de errores: Identificar patrones de fallo\n",
    "\n",
    "**Pr√≥ximo paso:** Despliegue y monitorizaci√≥n (notebook 05)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
