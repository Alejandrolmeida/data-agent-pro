{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f971a8ad",
   "metadata": {},
   "source": [
    "# 02 - Preparaci√≥n de Datos y Feature Engineering\n",
    "\n",
    "Este notebook demuestra t√©cnicas de transformaci√≥n y creaci√≥n de features usando Copilot.\n",
    "\n",
    "**Objetivos:**\n",
    "- Limpieza y transformaci√≥n de datos\n",
    "- Feature engineering\n",
    "- Escalado y normalizaci√≥n\n",
    "- Validaci√≥n con Pandera\n",
    "- Divisi√≥n train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c379db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandera as pa\n",
    "from pandera import Column, DataFrameSchema, Check\n",
    "\n",
    "print(\"‚úÖ Librer√≠as cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af971819",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos del Notebook Anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos explorados\n",
    "df = pd.read_parquet('./data/exploracion_completa.parquet')\n",
    "print(f\"Dataset cargado: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47d293",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "üí° **Copilot tip:** Usa `Ctrl+I` para generar features personalizadas basadas en domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas features\n",
    "df_engineered = df.copy()\n",
    "\n",
    "# Ejemplo: Interacciones entre features top\n",
    "df_engineered['feature_0_x_1'] = df['feature_0'] * df['feature_1']\n",
    "df_engineered['feature_0_squared'] = df['feature_0'] ** 2\n",
    "\n",
    "# Ratios\n",
    "df_engineered['feature_ratio_0_1'] = df['feature_0'] / (df['feature_1'] + 1e-8)\n",
    "\n",
    "# Agregaciones\n",
    "feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
    "df_engineered['feature_sum'] = df[feature_cols].sum(axis=1)\n",
    "df_engineered['feature_mean'] = df[feature_cols].mean(axis=1)\n",
    "df_engineered['feature_std'] = df[feature_cols].std(axis=1)\n",
    "\n",
    "print(f\"Features creadas. Shape: {df_engineered.shape}\")\n",
    "print(f\"Nuevas features: {df_engineered.shape[1] - df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b692c",
   "metadata": {},
   "source": [
    "## 3. Validaci√≥n de Schema con Pandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir schema esperado\n",
    "schema = DataFrameSchema(\n",
    "    {\n",
    "        \"feature_0\": Column(float, checks=Check.in_range(-5, 5)),\n",
    "        \"feature_1\": Column(float),\n",
    "        \"target\": Column(int, checks=Check.isin([0, 1])),\n",
    "        \"feature_sum\": Column(float, nullable=False),\n",
    "        \"feature_mean\": Column(float, nullable=False),\n",
    "    },\n",
    "    strict=False  # Permitir columnas adicionales\n",
    ")\n",
    "\n",
    "# Validar\n",
    "try:\n",
    "    validated_df = schema.validate(df_engineered)\n",
    "    print(\"‚úÖ Validaci√≥n de schema exitosa\")\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(f\"‚ùå Error de validaci√≥n: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478054d",
   "metadata": {},
   "source": [
    "## 4. Escalado de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed299cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features y target\n",
    "X = df_engineered.drop('target', axis=1)\n",
    "y = df_engineered['target']\n",
    "\n",
    "# Divisi√≥n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Escalado completado\")\n",
    "print(f\"Media train (post-escalado): {X_train_scaled.mean().mean():.6f}\")\n",
    "print(f\"Std train (post-escalado): {X_train_scaled.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd97ba7",
   "metadata": {},
   "source": [
    "## 5. Comparaci√≥n Before/After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c01511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Antes del escalado\n",
    "X_train['feature_0'].hist(bins=50, ax=axes[0], color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Antes del Escalado', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('feature_0')\n",
    "\n",
    "# Despu√©s del escalado\n",
    "X_train_scaled['feature_0'].hist(bins=50, ax=axes[1], color='salmon', edgecolor='black')\n",
    "axes[1].set_title('Despu√©s del Escalado', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('feature_0 (scaled)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71b624a",
   "metadata": {},
   "source": [
    "## 6. Guardar Datos Preparados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar datasets procesados\n",
    "X_train_scaled.to_parquet('./data/X_train.parquet')\n",
    "X_test_scaled.to_parquet('./data/X_test.parquet')\n",
    "y_train.to_frame().to_parquet('./data/y_train.parquet')\n",
    "y_test.to_frame().to_parquet('./data/y_test.parquet')\n",
    "\n",
    "# Guardar scaler para inference\n",
    "joblib.dump(scaler, './models/scaler.joblib')\n",
    "\n",
    "print(\"‚úÖ Datos preparados guardados\")\n",
    "print(\"‚úÖ Scaler guardado para inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf7982",
   "metadata": {},
   "source": [
    "## 7. Resumen\n",
    "\n",
    "**Transformaciones aplicadas:**\n",
    "- ‚úÖ Feature engineering (interacciones, ratios, agregaciones)\n",
    "- ‚úÖ Validaci√≥n de schema con Pandera\n",
    "- ‚úÖ Divisi√≥n train/test estratificada\n",
    "- ‚úÖ Escalado con StandardScaler\n",
    "\n",
    "**Pr√≥ximo paso:** Entrenamiento de modelos (notebook 03)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
