# üéì Workshop: MLOps en Azure con GitHub Copilot

> **Aprende a maximizar tu productividad en Data Science y MLOps usando GitHub Copilot potenciado con Servidores MCP**

![Workshop Banner](https://img.shields.io/badge/Duration-3.5%20hours-blue) ![Skill Level](https://img.shields.io/badge/Level-Intermediate-orange) ![Hands--on](https://img.shields.io/badge/Format-Hands--on-green)

---

## üìã Informaci√≥n del Workshop

### üéØ Objetivos de Aprendizaje

Al finalizar este workshop, ser√°s capaz de:

1. **Configurar y utilizar 8 servidores MCP** para potenciar GitHub Copilot en contextos de Data Science
2. **Acelerar el an√°lisis exploratorio** usando Python Data MCP y Jupyter MCP
3. **Implementar feature engineering** asistido por IA con sugerencias contextuales
4. **Automatizar tracking de experimentos** con Azure MCP y MLflow MCP
5. **Desplegar modelos en Azure ML** usando infraestructura como c√≥digo
6. **Crear workflows CI/CD** para ML con GitHub Actions y GitHub MCP

### üë• Audiencia

- **Data Scientists** que quieren acelerar su workflow
- **ML Engineers** interesados en MLOps en Azure
- **Desarrolladores** que trabajan con IA/ML
- **DevOps Engineers** enfocados en automatizaci√≥n de ML

### ‚è±Ô∏è Duraci√≥n

**3 horas 30 minutos** distribuidas en:

- üîß **M√≥dulo 1**: Setup y Verificaci√≥n de MCP Servers (30 min)
- üìä **M√≥dulo 2**: Exploraci√≥n y An√°lisis de Datos (45 min)
- üõ†Ô∏è **M√≥dulo 3**: Feature Engineering con Copilot (45 min)
- üöÄ **M√≥dulo 4**: Entrenamiento y MLOps en Azure (60 min)
- ‚öôÔ∏è **M√≥dulo 5**: CI/CD y Automatizaci√≥n (30 min)

### üìö Requisitos Previos

#### Conocimientos Necesarios

- ‚úÖ Python intermedio (pandas, numpy, scikit-learn)
- ‚úÖ Conocimientos b√°sicos de Machine Learning
- ‚úÖ Git y GitHub fundamentals
- ‚úÖ Conceptos b√°sicos de Azure (subscripciones, recursos)

#### Software Requerido

- ‚úÖ Visual Studio Code (√∫ltima versi√≥n)
- ‚úÖ GitHub Copilot (extensi√≥n activa)
- ‚úÖ Python 3.11 o superior
- ‚úÖ Azure CLI instalado y autenticado
- ‚úÖ Git configurado
- ‚úÖ Node.js 20+ (para servidores MCP npm)

#### Configuraci√≥n Previa

**‚ö†Ô∏è IMPORTANTE**: Debes haber completado el setup inicial del proyecto antes de empezar el workshop:

```bash
# Si a√∫n no lo has hecho, ejecuta:
./scripts/setup/initial-setup.sh
```

Esto configura:

- Azure Service Principal
- Azure ML Workspace
- GitHub Secrets
- Archivo .env con credenciales
- 8 Servidores MCP para GitHub Copilot

üìñ **Gu√≠a completa**: [docs/INITIAL_SETUP_README.md](INITIAL_SETUP_README.md)

---

## üìñ Agenda del Workshop

### üîß M√≥dulo 1: Setup y Verificaci√≥n de MCP Servers (30 min)

**Objetivo**: Asegurar que todos los servidores MCP est√°n funcionando correctamente y entender sus capacidades.

#### 1.1 Verificaci√≥n de Instalaci√≥n (10 min)

**Ejercicio 1.1.1: Verificar Servidores MCP**

1. Abre VS Code en la ra√≠z del proyecto
2. Presiona `Ctrl+Shift+I` para abrir GitHub Copilot Chat
3. Pregunta: `@workspace ¬øQu√© servidores MCP tienes disponibles?`

**Resultado esperado**: Deber√≠as ver los 8 servidores configurados:

- `azure-mcp`
- `python-data-mcp`
- `jupyter-mcp`
- `mlflow-mcp`
- `github-mcp`
- `filesystem-mcp`
- `brave-search-mcp`
- `memory-mcp`

**Ejercicio 1.1.2: Probar Azure MCP**

Pregunta a Copilot:

```
@workspace Usando el servidor MCP de Azure, lista los recursos 
del grupo rg-dataagent-dev
```

**Ejercicio 1.1.3: Probar Python Data MCP**

Pregunta a Copilot:

```
@workspace Usando el servidor MCP de Python Data, genera c√≥digo 
para cargar un CSV y mostrar estad√≠sticas descriptivas
```

#### 1.2 Exploraci√≥n de Capacidades (20 min)

**Ejercicio 1.2.1: Filesystem MCP**

Prueba el acceso optimizado a archivos:

```
@workspace Busca todos los archivos Python en el directorio scripts/ 
y explica qu√© hace cada uno
```

**Ejercicio 1.2.2: Memory MCP**

Prueba la memoria persistente:

```
@workspace Recuerda que en este proyecto prefiero usar MLflow para 
tracking y Azure ML para deployment. ¬øQu√© has guardado en memoria?
```

**Ejercicio 1.2.3: Brave Search MCP**

Prueba la b√∫squeda web:

```
@workspace Busca la documentaci√≥n m√°s reciente de Azure ML Python SDK 
para crear un endpoint online
```

**üéØ Checkpoint**: Al finalizar este m√≥dulo deber√≠as tener todos los servidores MCP funcionando y comprender qu√© hace cada uno.

---

### üìä M√≥dulo 2: Exploraci√≥n y An√°lisis de Datos (45 min)

**Objetivo**: Usar Copilot con MCP servers para acelerar el an√°lisis exploratorio de datos.

#### 2.1 Carga y Exploraci√≥n Inicial (15 min)

**Ejercicio 2.1.1: Crear Dataset de Ejemplo**

Crea un archivo `data/raw/customer_churn.csv` con datos sint√©ticos:

Pregunta a Copilot:

```
@workspace Genera un dataset sint√©tico de customer churn con 1000 registros 
que incluya: customer_id, tenure_months, monthly_charges, total_charges, 
contract_type, payment_method, tech_support, online_security, churn (0/1).
Gu√°rdalo en data/raw/customer_churn.csv
```

**Ejercicio 2.1.2: An√°lisis Exploratorio Asistido**

Abre el notebook `notebooks/01_exploracion.ipynb` y usa Copilot para:

1. Cargar el dataset y mostrar info b√°sica
2. Detectar valores nulos y tipos de datos
3. Generar estad√≠sticas descriptivas

**Prompt sugerido**:

```
Carga el dataset de data/raw/customer_churn.csv y realiza:
1. Verificaci√≥n de valores nulos
2. Estad√≠sticas descriptivas por variable
3. An√°lisis de distribuci√≥n de la variable target (churn)
```

#### 2.2 Visualizaciones (15 min)

**Ejercicio 2.2.1: Visualizaciones Autom√°ticas**

Usa Jupyter MCP para generar visualizaciones:

```
@workspace Genera visualizaciones para entender el churn:
1. Distribuci√≥n de churn por contract_type (barras)
2. Relaci√≥n entre monthly_charges y churn (boxplot)
3. Matriz de correlaci√≥n de variables num√©ricas
```

**Ejercicio 2.2.2: Dashboard Interactivo**

```
@workspace Crea un dashboard con plotly que muestre:
- KPIs principales (tasa de churn, promedio de charges, tenure)
- Distribuci√≥n de clientes por contrato
- An√°lisis de segmentaci√≥n
```

#### 2.3 Detecci√≥n de Anomal√≠as (15 min)

**Ejercicio 2.3.1: Outliers en Charges**

```
@workspace Usando scipy y pandas, detecta outliers en monthly_charges 
y total_charges usando el m√©todo IQR. Visualiza los resultados.
```

**Ejercicio 2.3.2: Validaci√≥n de Datos**

Crea un script de validaci√≥n con Pandera:

```
@workspace Crea un schema de Pandera para validar que:
- customer_id sea √∫nico y no nulo
- monthly_charges est√© entre 0 y 200
- tenure_months sea entero positivo
- churn sea 0 o 1
Aplica la validaci√≥n al dataset
```

**üéØ Checkpoint**: Deber√≠as tener un notebook completo de EDA con visualizaciones y validaci√≥n de datos generado en ~45 minutos (vs ~2-3 horas manualmente).

---

### üõ†Ô∏è M√≥dulo 3: Feature Engineering con Copilot (45 min)

**Objetivo**: Crear features efectivas usando sugerencias de IA y mejores pr√°cticas.

#### 3.1 Transformadores Custom (20 min)

**Ejercicio 3.1.1: Transformer de Encoding**

Abre `src/features/transformers.py` y pide a Copilot:

```
@workspace Crea un transformer scikit-learn que:
1. Haga one-hot encoding de contract_type y payment_method
2. Haga target encoding de tech_support y online_security usando el churn
3. Escale monthly_charges y total_charges con StandardScaler
4. Incluya manejo de valores nulos
```

**Ejercicio 3.1.2: Features de Negocio**

```
@workspace En src/features/features.py, crea funciones para generar:
1. customer_value: total_charges / tenure_months
2. price_per_service: monthly_charges dividido por n√∫mero de servicios contratados
3. contract_risk_score: combinaci√≥n de tenure, contract_type y payment_method
4. Incluye docstrings y type hints
```

#### 3.2 Pipeline Completo (15 min)

**Ejercicio 3.2.1: Crear Pipeline de Preprocessing**

Abre `notebooks/02_preparacion_datos.ipynb`:

```
@workspace Crea un Pipeline de scikit-learn que:
1. Use los transformadores creados anteriormente
2. Separe features num√©ricas y categ√≥ricas
3. Aplique ColumnTransformer
4. Incluya selecci√≥n de features con SelectKBest
5. Guarde el pipeline en models/preprocessing_pipeline.pkl
```

**Ejercicio 3.2.2: Validaci√≥n de Pipeline**

```
@workspace Genera c√≥digo para:
1. Aplicar el pipeline a train y test splits
2. Verificar que no hay data leakage
3. Mostrar las shapes resultantes
4. Guardar features procesadas en data/processed/
```

#### 3.3 Unit Tests (10 min)

**Ejercicio 3.3.1: Tests de Transformadores**

```
@workspace Crea tests en tests/test_transformers.py que verifiquen:
1. El transformer maneja valores nulos correctamente
2. El output tiene la dimensionalidad esperada
3. No hay data leakage entre train y test
4. Los valores est√°n en rangos v√°lidos despu√©s del scaling
```

**üéØ Checkpoint**: Deber√≠as tener un pipeline completo de feature engineering con tests automatizados.

---

### üöÄ M√≥dulo 4: Entrenamiento y MLOps en Azure (60 min)

**Objetivo**: Entrenar modelos, hacer tracking con MLflow y desplegar en Azure ML.

#### 4.1 Entrenamiento Local con MLflow (20 min)

**Ejercicio 4.1.1: Configurar MLflow Tracking**

Abre `notebooks/03_entrenamiento.ipynb`:

```
@workspace Configura MLflow para tracking local y entrena 3 modelos:
1. LogisticRegression con diferentes valores de C
2. RandomForest con diferentes max_depth
3. XGBoost con diferentes learning_rate
Loguea m√©tricas (accuracy, precision, recall, f1) y par√°metros
```

**Ejercicio 4.1.2: Hyperparameter Tuning**

```
@workspace Usa GridSearchCV para optimizar RandomForest y:
1. Loguea cada run con MLflow
2. Registra el mejor modelo
3. Guarda artifacts (matriz de confusi√≥n, feature importance)
4. Loguea el modelo con signature
```

#### 4.2 Azure ML Integration (20 min)

**Ejercicio 4.2.1: Crear Compute Cluster**

Pregunta a Copilot:

```
@workspace Usando Azure MCP, verifica si existe el compute cluster 
'cpu-cluster' en el workspace. Si no existe, muestra c√≥mo crearlo 
con el Azure ML SDK v2
```

**Ejercicio 4.2.2: Crear Training Job**

Edita `scripts/train/train.py`:

```
@workspace Modifica train.py para:
1. Cargar datos desde Azure ML Data Asset
2. Aplicar el pipeline de preprocessing
3. Entrenar el mejor modelo (del paso anterior)
4. Loguear en MLflow (Azure ML integrado)
5. Registrar modelo en Azure ML Model Registry
```

**Ejercicio 4.2.3: Submit Training Job**

Crea un script `scripts/train/submit_job.py`:

```
@workspace Crea un script que use Azure ML SDK v2 para:
1. Conectar al workspace usando las credenciales del .env
2. Crear un Command Job para ejecutar train.py
3. Usar el environment definido en aml/environments/training-conda.yml
4. Ejecutar en cpu-cluster
5. Mostrar el link al experimento en Azure ML Studio
```

#### 4.3 Model Evaluation (20 min)

**Ejercicio 4.3.1: Evaluaci√≥n Avanzada**

Abre `notebooks/04_evaluacion.ipynb`:

```
@workspace Eval√∫a el modelo registrado con:
1. Curvas ROC y PR
2. An√°lisis de feature importance con SHAP
3. Fairness analysis (comparar m√©tricas por segmentos)
4. Drift detection con Evidently AI
Guarda reportes en outputs/evaluation/
```

**Ejercicio 4.3.2: Comparaci√≥n de Modelos**

```
@workspace Usa MLflow MCP para:
1. Listar todos los experimentos del proyecto
2. Comparar las m√©tricas de los top 5 modelos
3. Generar un reporte markdown con la comparaci√≥n
4. Recomendar cu√°l modelo pasar a producci√≥n
```

**üéØ Checkpoint**: Deber√≠as tener modelos entrenados, trackeados en MLflow y registrados en Azure ML.

---

### ‚öôÔ∏è M√≥dulo 5: CI/CD y Automatizaci√≥n (30 min)

**Objetivo**: Automatizar deployment y crear workflows de CI/CD para ML.

#### 5.1 Deployment a Azure ML (15 min)

**Ejercicio 5.1.1: Crear Scoring Script**

Crea `scripts/deploy/score.py`:

```
@workspace Genera un scoring script para Azure ML Online Endpoint que:
1. Cargue el modelo desde MLflow
2. Cargue el preprocessing pipeline
3. Defina funci√≥n init() que cargue artefactos
4. Defina funci√≥n run(data) que procese JSON y retorne predicciones
5. Incluya manejo de errores y logging
```

**Ejercicio 5.1.2: Deploy Endpoint**

Edita `scripts/deploy/deploy_online_endpoint.py`:

```
@workspace Modifica el script para:
1. Conectar a Azure ML usando credenciales del .env
2. Crear o actualizar Online Endpoint
3. Crear Deployment con el modelo m√°s reciente
4. Asignar 100% del tr√°fico al nuevo deployment
5. Hacer una predicci√≥n de prueba
6. Mostrar la URL del endpoint
```

#### 5.2 GitHub Actions Workflow (15 min)

**Ejercicio 5.2.1: CI Workflow**

Pregunta a Copilot:

```
@workspace Usando GitHub MCP, crea un workflow .github/workflows/ci.yml que:
1. Se ejecute en cada push a main y PRs
2. Setup Python 3.11
3. Instale dependencias (requirements.txt)
4. Ejecute linters (black, flake8)
5. Ejecute tests con pytest
6. Genere reporte de coverage
```

**Ejercicio 5.2.2: CD Workflow para Model Training**

```
@workspace Crea .github/workflows/train-model.yml que:
1. Se ejecute manualmente (workflow_dispatch) o schedule semanal
2. Use Azure Login con el Service Principal (GitHub Secrets)
3. Submit training job a Azure ML
4. Espere a que termine el job
5. Si accuracy > 0.85, registre el modelo
6. Cree un comentario en la issue con los resultados
```

**Ejercicio 5.2.3: CD Workflow para Deployment**

```
@workspace Crea .github/workflows/deploy-model.yml que:
1. Se ejecute cuando se crea un nuevo release
2. Use Azure Login
3. Tome el modelo con tag "production" del Model Registry
4. Deploy a Online Endpoint
5. Ejecute smoke tests
6. Si falla, haga rollback autom√°tico
```

**üéØ Checkpoint Final**: Deber√≠as tener un pipeline completo de CI/CD automatizado desde c√≥digo hasta producci√≥n.

---

## üéì Recursos Adicionales

### üìö Learning Paths del Proyecto

- [Copilot para Ciencia de Datos](learning-paths/copilot-para-ciencia-de-datos.md)
- [Azure MLOps Profesional](learning-paths/azure-mlops-profesional.md)

### üîó Documentaci√≥n Oficial

- [Azure ML SDK v2](https://learn.microsoft.com/azure/machine-learning/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [GitHub Copilot Best Practices](https://github.blog/developer-skills/github/how-to-use-github-copilot-in-your-ide-tips-tricks-and-best-practices/)
- [Model Context Protocol](https://modelcontextprotocol.io/)

### üõ†Ô∏è Herramientas Mencionadas

- **Python Data MCP**: An√°lisis con pandas, numpy, scipy
- **Jupyter MCP**: Integraci√≥n con notebooks
- **MLflow MCP**: Tracking de experimentos
- **Azure MCP**: Gesti√≥n de recursos Azure
- **GitHub MCP**: Automatizaci√≥n de workflows
- **Filesystem MCP**: Navegaci√≥n optimizada
- **Brave Search MCP**: B√∫squeda de documentaci√≥n
- **Memory MCP**: Contexto persistente

---

## üìù Notas para el Instructor

### Timing Recomendado

- **No te adelantes demasiado**: Deja tiempo para que los participantes experimenten
- **Fomenta preguntas a Copilot**: El objetivo es que aprendan a formular buenos prompts
- **Haz checkpoints frecuentes**: Verifica que todos van al mismo ritmo

### Adaptaciones Posibles

**Si tienes m√°s tiempo (4-5 horas)**:

- A√±ade m√≥dulo de monitoring y retraining autom√°tico
- Profundiza en SHAP y explainabilidad
- A√±ade integraci√≥n con Databricks

**Si tienes menos tiempo (2-3 horas)**:

- Enf√≥cate en M√≥dulos 1, 2 y 4
- Haz demos del M√≥dulo 5 en lugar de ejercicios hands-on

### Troubleshooting Com√∫n

**"Los servidores MCP no aparecen"**

- Verifica que se ejecut√≥ `./scripts/setup/mcp-setup.sh`
- Reinicia VS Code completamente
- Revisa que el archivo `mcp.json` est√° en la ra√≠z

**"Error de autenticaci√≥n en Azure"**

- Verifica credenciales en `.env`
- Ejecuta `az login` de nuevo
- Confirma permisos del Service Principal

**"MLflow no loguea m√©tricas"**

- Verifica que `MLFLOW_TRACKING_URI` apunta al workspace de Azure ML
- Confirma que el experimento existe
- Revisa logs con `mlflow.set_tracking_uri()`

---

## üèÜ Certificado de Finalizaci√≥n

Al completar todos los m√≥dulos del workshop, habr√°s demostrado competencia en:

- ‚úÖ **Setup de entorno profesional** de MLOps
- ‚úÖ **Uso avanzado de GitHub Copilot** con servidores MCP
- ‚úÖ **Desarrollo acelerado** de pipelines de ML
- ‚úÖ **Deployment en Azure ML** con best practices
- ‚úÖ **Automatizaci√≥n CI/CD** para Machine Learning

---

## üìû Soporte

¬øPreguntas sobre el workshop?

- üìß **Issues**: [github.com/alejandrolmeida/data-agent-pro/issues](https://github.com/alejandrolmeida/data-agent-pro/issues)
- üí¨ **Discussions**: [github.com/alejandrolmeida/data-agent-pro/discussions](https://github.com/alejandrolmeida/data-agent-pro/discussions)

---

## üìÑ Licencia

Este workshop es parte del proyecto Data Agent Pro bajo licencia MIT.

**¬°Disfruta el workshop y maximiza tu productividad con GitHub Copilot! üöÄ**
