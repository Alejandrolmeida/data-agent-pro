# ü§ñ GitHub Copilot para Ciencia de Datos en Azure

Una gu√≠a completa para maximizar tu productividad como Data Scientist usando GitHub Copilot y Azure ML.

## üìö Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Configuraci√≥n Inicial](#configuraci√≥n-inicial)
3. [Workflows Fundamentales](#workflows-fundamentales)
4. [T√©cnicas Avanzadas](#t√©cnicas-avanzadas)
5. [Mejores Pr√°cticas](#mejores-pr√°cticas)
6. [Casos de Uso Reales](#casos-de-uso-reales)

---

## Introducci√≥n

### ¬øPor qu√© Copilot para Data Science?

GitHub Copilot acelera significativamente el trabajo de cient√≠ficos de datos al:

- **Generar c√≥digo boilerplate** para EDA, visualizaciones y modelos
- **Sugerir transformaciones** de datos basadas en contexto
- **Completar pipelines** de ML autom√°ticamente
- **Detectar errores** antes de ejecutar c√≥digo
- **Generar documentaci√≥n** inline y docstrings

### ROI Estimado

- ‚è±Ô∏è **40-50% reducci√≥n** en tiempo de codificaci√≥n
- üêõ **30% menos bugs** gracias a sugerencias context-aware
- üìñ **Documentaci√≥n autom√°tica** de funciones y pipelines
- üß™ **Generaci√≥n r√°pida** de unit tests

---

## Configuraci√≥n Inicial

### 1. Instalar Extensiones Esenciales

```bash
code --install-extension GitHub.copilot
code --install-extension GitHub.copilot-chat
code --install-extension ms-toolsai.jupyter
code --install-extension ms-python.python
```

### 2. Configurar Shortcuts

**Atajos clave para productividad:**

| Acci√≥n | Atajo | Uso |
|--------|-------|-----|
| Aceptar sugerencia | `Tab` | Acepta la sugerencia completa |
| Ver alternativas | `Alt+]` / `Alt+[` | Navega entre sugerencias |
| Abrir chat | `Ctrl+I` | Iniciar conversaci√≥n inline |
| Copilot Chat | `Ctrl+Shift+I` | Panel de chat lateral |
| Explicar c√≥digo | `Ctrl+I` ‚Üí `/explain` | Explica bloque seleccionado |

### 3. Habilitar Chat Modes

Copia los archivos de `.github/chatmodes/` a tu workspace para activar modos especializados:

- **@azure-ds-agent**: Asistente de Data Science
- **@azure-mlops-engineer**: MLOps y despliegues
- **@azure-aisec-agent**: Seguridad en ML

---

## Workflows Fundamentales

### Workflow 1: Exploraci√≥n de Datos (EDA)

#### ‚úÖ Paso 1: Generar resumen estad√≠stico

**Prompt en Copilot Chat:**

```
Crea una funci√≥n que genere un resumen estad√≠stico completo de un DataFrame de pandas, 
incluyendo missing values, tipos de datos, distribuciones y correlaciones
```

**Resultado esperado:**

```python
def generate_eda_report(df: pd.DataFrame) -> dict:
    """
    Genera un reporte completo de an√°lisis exploratorio.
    
    Args:
        df: DataFrame a analizar
        
    Returns:
        dict: Diccionario con m√©tricas y hallazgos
    """
    report = {
        'shape': df.shape,
        'missing_values': df.isnull().sum().to_dict(),
        'dtypes': df.dtypes.to_dict(),
        'summary_stats': df.describe().to_dict(),
        'correlations': df.corr().to_dict()
    }
    return report
```

#### ‚úÖ Paso 2: Generar visualizaciones autom√°ticas

**Inline prompt (comentario):**

```python
# Crea un dashboard con 4 subplots: histograma de target, boxplot de features num√©ricas,
# heatmap de correlaci√≥n y gr√°fico de valores nulos
```

**Copilot generar√°:**

```python
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Histograma de target
df['target'].hist(ax=axes[0, 0], bins=50)
axes[0, 0].set_title('Distribuci√≥n de Target')

# Boxplot de features num√©ricas
df.select_dtypes(include=[np.number]).boxplot(ax=axes[0, 1])
axes[0, 1].set_title('Boxplot de Features')

# Heatmap de correlaci√≥n
sns.heatmap(df.corr(), ax=axes[1, 0], cmap='coolwarm', center=0)
axes[1, 0].set_title('Matriz de Correlaci√≥n')

# Valores nulos
df.isnull().sum().plot(kind='bar', ax=axes[1, 1])
axes[1, 1].set_title('Valores Nulos por Columna')

plt.tight_layout()
plt.show()
```

#### üéØ Pro Tips

- Usa **comentarios descriptivos** antes de bloques de c√≥digo
- Especifica **libraries preferidas** (ej: "usando seaborn")
- Indica **dimensiones** y **estilos** de visualizaci√≥n

---

### Workflow 2: Feature Engineering

#### ‚úÖ Paso 1: Generar transformaciones comunes

**Prompt:**

```
Crea una clase FeatureTransformer con m√©todos para:
- Escalado robusto a outliers
- Encoding de categ√≥ricas con target encoding
- Creaci√≥n de features de interacci√≥n
- Detecci√≥n de features redundantes
```

**Copilot sugerir√°:**

```python
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import RobustScaler
import category_encoders as ce

class FeatureTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, target_col: str = 'target'):
        self.target_col = target_col
        self.scaler = RobustScaler()
        self.encoder = ce.TargetEncoder()
        
    def fit(self, X, y=None):
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        self.scaler.fit(X[numeric_cols])
        
        categorical_cols = X.select_dtypes(include=['object']).columns
        if len(categorical_cols) > 0:
            self.encoder.fit(X[categorical_cols], y)
        
        return self
    
    def transform(self, X):
        X_transformed = X.copy()
        
        # Escalar num√©ricos
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        X_transformed[numeric_cols] = self.scaler.transform(X[numeric_cols])
        
        # Encodear categ√≥ricos
        categorical_cols = X.select_dtypes(include=['object']).columns
        if len(categorical_cols) > 0:
            X_transformed[categorical_cols] = self.encoder.transform(X[categorical_cols])
        
        return X_transformed
```

#### ‚úÖ Paso 2: Generar features de dominio

**Inline con contexto:**

```python
# Dataset: transacciones bancarias con columnas 'amount', 'timestamp', 'merchant_category'
# Objetivo: detectar fraude
# Crea features: ratio amount/avg_by_category, hour_of_day, is_weekend, transaction_velocity
```

---

### Workflow 3: Entrenamiento de Modelos

#### ‚úÖ Paso 1: Pipeline completo con MLflow

**Prompt en Chat:**

```
Crea una funci√≥n train_with_mlflow que:
1. Cargue datos desde Azure Data Lake
2. Divida en train/test
3. Entrene RandomForest, XGBoost y LightGBM
4. Registre m√©tricas en MLflow
5. Guarde el mejor modelo
6. Use cross-validation de 5 folds
```

#### ‚úÖ Paso 2: Optimizaci√≥n de hiperpar√°metros

**Comentario inline:**

```python
# Usa Optuna para optimizar XGBoost con estos objetivos:
# - Maximizar F1 score
# - 50 trials
# - Early stopping si no mejora en 10 trials
# - Hiperpar√°metros: n_estimators, max_depth, learning_rate, subsample
```

#### üéØ Pro Tips

- Especifica **framework de tracking** (MLflow, Weights & Biases)
- Indica **m√©tricas objetivo** claramente
- Menciona **constraints** (ej: tiempo max, memoria)

---

### Workflow 4: Validaci√≥n de Datos

#### ‚úÖ Paso 1: Schemas con Pandera

**Prompt:**

```
Genera un schema Pandera para validar un dataset de ventas con:
- order_id: string √∫nico
- customer_id: int positivo
- amount: float entre 0 y 10000
- timestamp: datetime no nulo
- status: uno de ['pending', 'completed', 'cancelled']
```

**Copilot generar√°:**

```python
import pandera as pa
from pandera import Column, DataFrameSchema, Check

sales_schema = DataFrameSchema({
    "order_id": Column(str, checks=[
        Check.str_matches(r'^ORD-\d{6}$'),
        Check(lambda s: s.is_unique)
    ]),
    "customer_id": Column(int, checks=Check.greater_than(0)),
    "amount": Column(float, checks=Check.in_range(0, 10000)),
    "timestamp": Column(pa.DateTime, nullable=False),
    "status": Column(str, checks=Check.isin(['pending', 'completed', 'cancelled']))
})
```

#### ‚úÖ Paso 2: Great Expectations

**Prompt:**

```
Crea expectativas para un dataset de sensores IoT:
- temperatura: entre -40 y 120 grados
- humedad: 0-100%
- no m√°s de 5% de valores nulos
- timestamp creciente
```

---

## T√©cnicas Avanzadas

### 1. Generaci√≥n de Tests Autom√°ticos

**Selecciona una funci√≥n y usa:**

```
Ctrl+I ‚Üí /tests
```

**Ejemplo de output:**

```python
import pytest
from src.features.features import calculate_rolling_statistics

def test_calculate_rolling_statistics_basic():
    data = pd.DataFrame({'value': [1, 2, 3, 4, 5]})
    result = calculate_rolling_statistics(data, window=3)
    assert len(result) == len(data)
    assert 'value_rolling_mean' in result.columns

def test_calculate_rolling_statistics_edge_cases():
    # Empty dataframe
    empty_df = pd.DataFrame()
    with pytest.raises(ValueError):
        calculate_rolling_statistics(empty_df, window=3)
    
    # Window size larger than data
    small_df = pd.DataFrame({'value': [1, 2]})
    result = calculate_rolling_statistics(small_df, window=5)
    assert result['value_rolling_mean'].isna().sum() >= 2
```

### 2. Documentaci√≥n Autom√°tica

**Selecciona funci√≥n sin docstring:**

```
Ctrl+I ‚Üí /doc
```

**Copilot a√±adir√°:**

```python
def preprocess_text(text: str, remove_stopwords: bool = True) -> List[str]:
    """
    Procesa texto para an√°lisis de NLP.
    
    Realiza limpieza, tokenizaci√≥n y opcionalmente elimina stopwords.
    
    Args:
        text: Texto a procesar (puede contener HTML, URLs, emojis)
        remove_stopwords: Si True, elimina palabras comunes en espa√±ol
        
    Returns:
        Lista de tokens limpios y normalizados
        
    Examples:
        >>> preprocess_text("¬°Hola mundo! https://example.com üòä")
        ['hola', 'mundo']
        
        >>> preprocess_text("Python es genial", remove_stopwords=False)
        ['python', 'es', 'genial']
    """
    # ... c√≥digo
```

### 3. Refactoring Inteligente

**Selecciona c√≥digo legacy:**

```
Ctrl+I ‚Üí "Refactoriza esto siguiendo principios SOLID y a√±ade type hints"
```

### 4. Generaci√≥n de Notebooks

**Prompt en Chat:**

```
Crea un notebook Jupyter para an√°lisis de churn con:
1. Carga de datos desde Azure SQL
2. EDA con pandas-profiling
3. Feature engineering (RFM analysis)
4. Entrenamiento de 3 modelos
5. Comparaci√≥n con gr√°ficos
6. Exportaci√≥n de mejor modelo a ONNX
```

---

## Mejores Pr√°cticas

### ‚úÖ DO: Contexto Rico

**Bueno:**

```python
# Dataset: transacciones con columnas [user_id, amount, timestamp, category]
# Objetivo: predecir probabilidad de compra en pr√≥ximos 7 d√≠as
# Crea features RFM (Recency, Frequency, Monetary)
```

**Malo:**

```python
# crea features
```

### ‚úÖ DO: Especificar Constraints

```python
# Carga dataset manteniendo memoria < 2GB
# Usa chunking si es necesario
```

### ‚úÖ DO: Mencionar Frameworks

```python
# Usando Azure ML SDK v2 y MLflow, no v1
```

### ‚ùå DON'T: Confiar Ciegamente

Siempre **revisa** c√≥digo generado:

- ‚úÖ Imports correctos
- ‚úÖ Manejo de errores
- ‚úÖ Performance (evita loops innecesarios)
- ‚úÖ Seguridad (no hardcodear secretos)

### ‚ùå DON'T: Prompts Ambiguos

**Malo:** "haz un modelo"

**Bueno:** "Entrena un XGBoost para clasificaci√≥n multiclase (5 clases), optimiza F1-macro con Optuna, 100 trials"

---

## Casos de Uso Reales

### Caso 1: An√°lisis de Sentimientos en Redes Sociales

**Prompt completo:**

```
Necesito un pipeline de an√°lisis de sentimientos para tweets en espa√±ol:

1. Preprocesamiento:
   - Eliminar URLs, menciones, hashtags
   - Normalizar emojis a texto
   - Lematizaci√≥n con spaCy es_core_news_md
   
2. Feature extraction:
   - TF-IDF (max_features=5000)
   - Embedding con sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
   
3. Modelo:
   - LSTM bidireccional con attention
   - Optimizador Adam, lr=0.001
   - Early stopping con patience=5
   
4. Validaci√≥n:
   - Stratified K-Fold (5 folds)
   - M√©tricas: Accuracy, F1-weighted, Confusion Matrix
   
5. Deployment:
   - FastAPI endpoint en Azure Container Apps
   - Input: texto crudo, Output: {sentiment, confidence, probabilities}
```

**Copilot generar√° 200-300 l√≠neas de c√≥digo funcional.**

### Caso 2: Sistema de Recomendaci√≥n

**Prompt:**

```
Implementa un sistema de recomendaci√≥n h√≠brido:

Datos:
- user_ratings.csv: [user_id, item_id, rating, timestamp]
- item_features.csv: [item_id, category, price, brand]
- user_features.csv: [user_id, age_group, location]

Enfoques a combinar:
1. Collaborative Filtering: Matrix Factorization (ALS de Spark)
2. Content-Based: Cosine similarity en item_features
3. Hybrid: Weighted average (70% CF, 30% CB)

Output esperado:
- Funci√≥n recommend(user_id, top_k=10) -> List[item_id]
- Evaluaci√≥n con NDCG@10 y MAP@10
- Pipeline batch en Azure Databricks

Constraints:
- 10M users, 1M items
- Latencia < 100ms para online serving
- Actualizaci√≥n diaria del modelo
```

---

## Recursos Adicionales

### üìñ Documentaci√≥n Oficial

- [GitHub Copilot Docs](https://docs.github.com/en/copilot)
- [Azure ML Python SDK v2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-model)

### üéì Cursos Recomendados

- [Microsoft Learn: AI-102](https://learn.microsoft.com/en-us/certifications/exams/ai-102/)
- [Copilot for Data Science (LinkedIn Learning)](https://www.linkedin.com/learning/)

### üõ†Ô∏è Herramientas Complementarias

- **MLflow**: Tracking de experimentos
- **Great Expectations**: Validaci√≥n de datos
- **Evidently AI**: Monitoreo de drift
- **SHAP**: Explicabilidad de modelos

---

## üöÄ Pr√≥ximos Pasos

1. ‚úÖ Completa el tutorial de [Azure MLOps Profesional](./azure-mlops-profesional.md)
2. ‚úÖ Explora [Cheatsheet de Pandas con Copilot](../cheatsheets/pandas-copilot.md)
3. ‚úÖ Prueba los [3 tutoriales pr√°cticos](../tutorials/)
4. ‚úÖ Contribuye mejorando estos docs üôå

---

**¬øPreguntas?** Abre un issue en el repositorio o contacta al equipo de ML Platform.

**√öltima actualizaci√≥n:** 2024
**Autor:** Data Agent Pro Team
**Licencia:** MIT
