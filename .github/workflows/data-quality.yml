name: Data Quality Validation

on:
  push:
    branches: [main, develop]
    paths:
      - 'data/**'
      - 'scripts/data/**'
      - '.github/workflows/data-quality.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'data/**'
      - 'scripts/data/**'
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'

jobs:
  data-validation:
    name: Validate Data Quality
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write  # For Azure OIDC

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install great-expectations==0.18.8 pandas openpyxl
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Azure Login (OIDC)
        if: github.event_name != 'pull_request'
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Run Great Expectations
        id: ge_validation
        run: |
          echo "Running Great Expectations validations..."
          python scripts/data/validate.py
        env:
          AZURE_STORAGE_ACCOUNT: ${{ vars.AZURE_STORAGE_ACCOUNT }}
          AZURE_STORAGE_CONTAINER: ${{ vars.AZURE_STORAGE_CONTAINER }}

      - name: Generate Data Docs
        if: always()
        run: |
          # Great Expectations genera documentación HTML
          if [ -d "great_expectations/uncommitted/data_docs" ]; then
            echo "Data docs generated successfully"
          fi

      - name: Upload Data Docs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: data-docs-${{ github.run_number }}
          path: great_expectations/uncommitted/data_docs/
          retention-days: 30

      - name: Check validation results
        if: always()
        run: |
          # Fail if validation encontró issues críticos
          if [ -f "validation_results.json" ]; then
            python - <<'EOF'
          import json
          import sys
          
          with open('validation_results.json') as f:
              results = json.load(f)
          
          if not results.get('success', True):
              print("❌ Data quality validation failed!")
              sys.exit(1)
          else:
              print("✅ Data quality validation passed!")
          EOF
          fi

      - name: Comment PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let comment = '## Data Quality Validation Results\n\n';
            
            try {
              const results = JSON.parse(fs.readFileSync('validation_results.json', 'utf8'));
              comment += results.success ? '✅ All validations passed!\n' : '❌ Some validations failed\n';
              comment += `\n**Details**: See [artifacts](${context.payload.repository.html_url}/actions/runs/${context.runId})`;
            } catch (e) {
              comment += '⚠️ Could not read validation results';
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  schema-validation:
    name: Validate Data Schemas
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install pandas pandera pydantic

      - name: Validate schemas
        run: |
          python - <<'EOF'
          import pandas as pd
          import pandera as pa
          from pathlib import Path
          
          # Define schema esperado
          schema = pa.DataFrameSchema({
              "id": pa.Column(int, pa.Check.greater_than(0)),
              "value": pa.Column(float, nullable=True),
              "category": pa.Column(str, pa.Check.isin(["A", "B", "C"]))
          })
          
          # Validar archivos en data/samples
          samples_dir = Path("data/samples")
          if samples_dir.exists():
              for csv_file in samples_dir.glob("*.csv"):
                  print(f"Validating {csv_file.name}...")
                  df = pd.read_csv(csv_file)
                  try:
                      schema.validate(df, lazy=True)
                      print(f"✅ {csv_file.name} passed schema validation")
                  except pa.errors.SchemaErrors as e:
                      print(f"❌ {csv_file.name} failed schema validation:")
                      print(e)
                      exit(1)
          else:
              print("No sample data found, skipping schema validation")
          EOF
