{
  "Azure ML Training Job": {
    "prefix": "aml-train",
    "body": [
      "from azure.ai.ml import MLClient, command",
      "from azure.ai.ml.entities import Environment",
      "from azure.identity import DefaultAzureCredential",
      "",
      "ml_client = MLClient(",
      "    credential=DefaultAzureCredential(),",
      "    subscription_id=\"${1:subscription_id}\",",
      "    resource_group_name=\"${2:resource_group}\",",
      "    workspace_name=\"${3:workspace}\"",
      ")",
      "",
      "job = command(",
      "    code=\"./src\",",
      "    command=\"python train.py --data \\${{inputs.data}}\",",
      "    inputs={\"data\": Input(type=\"uri_folder\", path=\"${4:data_path}\")},",
      "    environment=\"${5:training-env}@latest\",",
      "    compute=\"${6:cpu-cluster}\",",
      "    experiment_name=\"${7:experiment}\"",
      ")",
      "",
      "returned_job = ml_client.jobs.create_or_update(job)",
      "print(f\"Job: {returned_job.name}\")"
    ],
    "description": "Azure ML training job template"
  },
  
  "MLflow Tracking": {
    "prefix": "mlflow-track",
    "body": [
      "import mlflow",
      "",
      "mlflow.set_experiment(\"${1:experiment_name}\")",
      "",
      "with mlflow.start_run():",
      "    # Log parameters",
      "    mlflow.log_params({",
      "        \"${2:param_name}\": ${3:param_value}",
      "    })",
      "    ",
      "    # Training code here",
      "    ${4:# model = train(...)}",
      "    ",
      "    # Log metrics",
      "    mlflow.log_metrics({",
      "        \"${5:metric_name}\": ${6:metric_value}",
      "    })",
      "    ",
      "    # Log model",
      "    mlflow.sklearn.log_model(${7:model}, \"model\")"
    ],
    "description": "MLflow experiment tracking template"
  },
  
  "Pandas EDA": {
    "prefix": "pd-eda",
    "body": [
      "import pandas as pd",
      "import numpy as np",
      "import matplotlib.pyplot as plt",
      "import seaborn as sns",
      "",
      "# Load data",
      "df = pd.read_csv(\"${1:data.csv}\")",
      "",
      "# Basic info",
      "print(\"Shape:\", df.shape)",
      "print(\"\\nInfo:\")",
      "df.info()",
      "",
      "# Summary statistics",
      "print(\"\\nStatistics:\")",
      "print(df.describe())",
      "",
      "# Missing values",
      "print(\"\\nMissing values:\")",
      "print(df.isnull().sum())",
      "",
      "# Visualizations",
      "fig, axes = plt.subplots(2, 2, figsize=(12, 10))",
      "",
      "# Distribution",
      "df[\"${2:column}\"].hist(ax=axes[0, 0])",
      "axes[0, 0].set_title(\"Distribution\")",
      "",
      "# Boxplot",
      "df.boxplot(column=\"${2:column}\", ax=axes[0, 1])",
      "",
      "# Correlation heatmap",
      "sns.heatmap(df.corr(), annot=True, ax=axes[1, 0])",
      "",
      "plt.tight_layout()",
      "plt.show()"
    ],
    "description": "Pandas exploratory data analysis template"
  },
  
  "Scikit-learn Pipeline": {
    "prefix": "sklearn-pipeline",
    "body": [
      "from sklearn.pipeline import Pipeline",
      "from sklearn.preprocessing import StandardScaler",
      "from sklearn.impute import SimpleImputer",
      "from sklearn.compose import ColumnTransformer",
      "from sklearn.${1:ensemble} import ${2:RandomForestClassifier}",
      "",
      "# Numeric transformer",
      "numeric_transformer = Pipeline(steps=[",
      "    ('imputer', SimpleImputer(strategy='median')),",
      "    ('scaler', StandardScaler())",
      "])",
      "",
      "# Categorical transformer",
      "categorical_transformer = Pipeline(steps=[",
      "    ('imputer', SimpleImputer(strategy='most_frequent')),",
      "    ('onehot', OneHotEncoder(handle_unknown='ignore'))",
      "])",
      "",
      "# Preprocessor",
      "preprocessor = ColumnTransformer(",
      "    transformers=[",
      "        ('num', numeric_transformer, ${3:numeric_features}),",
      "        ('cat', categorical_transformer, ${4:categorical_features})",
      "    ])",
      "",
      "# Full pipeline",
      "pipeline = Pipeline(steps=[",
      "    ('preprocessor', preprocessor),",
      "    ('classifier', ${2:RandomForestClassifier}())",
      "])",
      "",
      "# Fit",
      "pipeline.fit(X_train, y_train)",
      "",
      "# Predict",
      "y_pred = pipeline.predict(X_test)"
    ],
    "description": "Scikit-learn preprocessing and modeling pipeline"
  },
  
  "Great Expectations Suite": {
    "prefix": "ge-suite",
    "body": [
      "import great_expectations as ge",
      "from great_expectations.data_context import DataContext",
      "",
      "# Initialize context",
      "context = DataContext(\"${1:./great_expectations}\")",
      "",
      "# Create expectation suite",
      "suite = context.create_expectation_suite(",
      "    expectation_suite_name=\"${2:suite_name}\",",
      "    overwrite_existing=True",
      ")",
      "",
      "# Load data",
      "df = ge.read_csv(\"${3:data.csv}\")",
      "",
      "# Add expectations",
      "df.expect_table_row_count_to_be_between(min_value=${4:100}, max_value=${5:10000})",
      "df.expect_column_values_to_not_be_null(\"${6:column_name}\")",
      "df.expect_column_values_to_be_between(",
      "    column=\"${7:numeric_column}\",",
      "    min_value=${8:0},",
      "    max_value=${9:100}",
      ")",
      "",
      "# Save suite",
      "df.save_expectation_suite()"
    ],
    "description": "Great Expectations validation suite"
  },
  
  "Azure Managed Endpoint": {
    "prefix": "aml-endpoint",
    "body": [
      "from azure.ai.ml import MLClient",
      "from azure.ai.ml.entities import (",
      "    ManagedOnlineEndpoint,",
      "    ManagedOnlineDeployment,",
      "    Model,",
      "    Environment,",
      "    CodeConfiguration",
      ")",
      "from azure.identity import DefaultAzureCredential",
      "",
      "ml_client = MLClient(",
      "    DefaultAzureCredential(),",
      "    subscription_id=\"${1:subscription_id}\",",
      "    resource_group_name=\"${2:resource_group}\",",
      "    workspace_name=\"${3:workspace}\"",
      ")",
      "",
      "# Create endpoint",
      "endpoint = ManagedOnlineEndpoint(",
      "    name=\"${4:endpoint-name}\",",
      "    description=\"${5:Endpoint description}\",",
      "    auth_mode=\"key\"",
      ")",
      "",
      "ml_client.online_endpoints.begin_create_or_update(endpoint).result()",
      "",
      "# Create deployment",
      "deployment = ManagedOnlineDeployment(",
      "    name=\"${6:blue}\",",
      "    endpoint_name=\"${4:endpoint-name}\",",
      "    model=\"${7:model_name}:${8:1}\",",
      "    instance_type=\"${9:Standard_DS3_v2}\",",
      "    instance_count=${10:1}",
      ")",
      "",
      "ml_client.online_deployments.begin_create_or_update(deployment).result()",
      "",
      "# Set traffic",
      "endpoint.traffic = {\"${6:blue}\": 100}",
      "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
    ],
    "description": "Azure ML managed online endpoint deployment"
  },
  
  "Pytest Fixture": {
    "prefix": "pytest-fixture",
    "body": [
      "import pytest",
      "import pandas as pd",
      "",
      "@pytest.fixture",
      "def ${1:sample_data}():",
      "    \"\"\"${2:Fixture description}\"\"\"",
      "    return pd.DataFrame({",
      "        \"${3:column}\": [${4:1, 2, 3}]",
      "    })",
      "",
      "def test_${5:function_name}(${1:sample_data}):",
      "    \"\"\"${6:Test description}\"\"\"",
      "    ${7:# Test code}",
      "    assert ${8:condition}"
    ],
    "description": "Pytest fixture and test template"
  }
}
